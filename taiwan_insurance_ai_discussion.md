# 台灣保險業生成式 AI 導入與開發討論研究 (2026-02-03)

## 1. 台灣金融/保險業導入現況 (論壇與非正式討論摘要)

由於金融業高度監管，許多具體的導入細節（如 Prompt 內容、內部整合方式）多存在於非公開的閉門會議或內部技術分享。以下是彙整自 iThome、PTT 職涯板、以及相關技術社群的討論觀察：

### A. 實踐層面：從「個人」到「企業」的轉變
*   **非正式階段**：早期多為開發者「自帶工具」(BYOAI)，使用個人帳號私下輔助寫代碼。
*   **正式階段 (現況)**：大型金控（如國泰、富邦、中信、玉山等）已開始正式進行企業版（Copilot for Business/Enterprise）的 POC 測試，重點轉向「數據不出境」與「資安合規」。

### B. 產險業核心應用場景 (討論熱點)
*   **Legacy Code 轉置**：許多產險系統仍使用舊版 .NET 或 Java，論壇討論多集中在如何利用 Copilot 將舊代碼重構為微服務架構，並自動產生單元測試。
*   **文件自動化**：討論如何利用 RAG (檢索增強生成) 技術，讓 AI 學習「核保手冊」與「理賠規範 PDF」，解決新人核保員查詢手冊時間過長的問題。

---

## 2. 監管合規架構 (台灣金管會核心原則)

根據 2023-2024 年金管會公布的「金融業運用 AI 核心原則」，企業導入 Copilot 必須符合以下討論焦點：

| 核心原則 | 企業應對策略 (根據論壇觀察) |
| :--- | :--- |
| **保護隱私與客戶權益** | **強制脫敏**：在傳輸至 Copilot 前，必須確保保單號碼、身分證字號等 PII 被過濾（去識別化）。 |
| **落實透明性與可解釋性** | **稽核日誌**：企業傾向使用 GitHub Audit Logs 監控 AI 產出的代碼占比與變動軌跡。 |
| **確保系統穩健性與安全性** | **內部模型隔離**：部分金控討論使用 Azure OpenAI 搭建內部的 GitHub Copilot Proxy，確保數據僅在受控區域流動。 |

---

## 3. 台灣保險業導入的隱形挑戰 (非公開反饋)

*   **「黑盒」疑慮**：產險精算與理賠邏輯極其精確，開發者在論壇中反映，AI 產出的複雜數學邏輯仍需人工嚴格校對，無法完全取代精算師。
*   **法遵與稽核的拉鋸**：法遵部門常對「代碼片段傳輸至雲端」感到不安，導致企業在推行時，往往需要搭配極其嚴格的網路代理 (Proxy) 設定。
*   **Prompt 敏感度**：內部討論如何建立「Prompt 安全規範」，防止開發者在詢問 AI 時無意間透露內部業務邏輯。

---

## 4. 研究結論：產險業的「安全導入路徑」

目前台灣產險業最安全的導入方式傾向於：
1.  **前端脫敏**：建立如 `pii_masking.md` 所述的攔截機制。
2.  **後端審核**：AI 產出的每一行代碼都必須標註為「AI 生成」，並由資深架構師進行二次 Code Review。
3.  **封閉式 RAG**：將理賠手冊等敏感文檔放在內網（如 Wiki.js），透過 OpenClaw 或自建 LLM 處理，而不直接餵給公有雲。

相關研究內容已同步更新至 `gh-copilot-enterprise-security-research/case_studies.md`。
